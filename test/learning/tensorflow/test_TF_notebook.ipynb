{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `TFNoiseAwareModel`\n",
    "\n",
    "We'll start by testing the `textRNN` model on a categorical problem from `tutorials/crowdsourcing`.  In particular we'll test for (a) basic performance and (b) proper construction / re-construction of the TF computation graph both after (i) repeated notebook calls, and (ii) with `GridSearch` in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "% matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['SNORKELDB'] = 'sqlite:///{0}{1}crowdsourcing.db'.format(os.getcwd(), os.sep)\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load candidates and training marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.contrib.models.text import RawText\n",
    "Tweet = candidate_subclass('Tweet', ['tweet'], cardinality=5)\n",
    "train_tweets = session.query(Tweet).filter(Tweet.split == 0).order_by(Tweet.id).all()\n",
    "len(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/gitcode/snorkel/snorkel/annotations.py\u001b[0m in \u001b[0;36mload_marginals\u001b[0;34m(session, X, split, cids_query, training)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mcardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m             \u001b[0mmarginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_candidate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-18b4376eb46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_marginals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_marginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_marginals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_marginals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/gitcode/snorkel/snorkel/annotations.py\u001b[0m in \u001b[0;36mload_marginals\u001b[0;34m(session, X, split, cids_query, training)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# Handle list of Candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mcardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mmarginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mcid_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, train_tweets, split=0)\n",
    "train_marginals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple unigram featurizer\n",
    "def get_unigram_tweet_features(c):\n",
    "    for w in c.tweet.text.split():\n",
    "        yield w, 1\n",
    "\n",
    "# Construct feature matrix\n",
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator(f=get_unigram_tweet_features)\n",
    "\n",
    "%time F_train = featurizer.apply(split=0)\n",
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time F_test = featurizer.apply_existing(split=1)\n",
    "F_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.tensorflow import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(cardinality=Tweet.cardinality)\n",
    "model.train(F_train.todense(), train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train `SparseLogisticRegression`\n",
    "\n",
    "Note: Testing doesn't currently work with `LogisticRegression` above, but no real reason to use that over this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.tensorflow import SparseLogisticRegression\n",
    "\n",
    "model = SparseLogisticRegression(cardinality=Tweet.cardinality)\n",
    "model.train(F_train, train_marginals, n_epochs=50, print_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_labels = np.load('crowdsourcing_test_labels.npy')\n",
    "acc = model.score(F_test, test_labels)\n",
    "print(acc)\n",
    "assert acc > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with batch size s.t. N % batch_size == 1...\n",
    "model.score(F_test, test_labels, batch_size=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train basic LSTM\n",
    "\n",
    "With dev set scoring during execution (note we use test set here to be simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.tensorflow import TextRNN\n",
    "test_tweets = session.query(Tweet).filter(Tweet.split == 1).order_by(Tweet.id).all()\n",
    "\n",
    "train_kwargs = {\n",
    "    'dim':        100,\n",
    "    'lr':         0.001,\n",
    "    'n_epochs':   25,\n",
    "    'dropout':    0.2,\n",
    "    'print_freq': 5\n",
    "}\n",
    "lstm = TextRNN(seed=123, cardinality=Tweet.cardinality)\n",
    "lstm.train(train_tweets, train_marginals, X_dev=test_tweets, Y_dev=test_labels, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = lstm.score(test_tweets, test_labels)\n",
    "print(acc)\n",
    "assert acc > 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with batch size s.t. N % batch_size == 1...\n",
    "lstm.score(test_tweets, test_labels, batch_size=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run `GridSearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.utils import GridSearch\n",
    "\n",
    "# Searching over learning rate\n",
    "param_ranges = {'lr': [1e-3, 1e-4], 'dim': [50, 100]}\n",
    "model_class_params = {'seed' : 123, 'cardinality': Tweet.cardinality}\n",
    "model_hyperparams = {\n",
    "    'dim':        100,\n",
    "    'n_epochs':   20,\n",
    "    'dropout':    0.1,\n",
    "    'print_freq': 10\n",
    "}\n",
    "searcher = GridSearch(TextRNN, param_ranges, train_tweets, train_marginals,\n",
    "                     model_class_params=model_class_params,\n",
    "                     model_hyperparams=model_hyperparams)\n",
    "\n",
    "# Use test set here (just for testing)\n",
    "lstm, run_stats = searcher.fit(test_tweets, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = lstm.score(test_tweets, test_labels)\n",
    "print(acc)\n",
    "assert acc > 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload saved model outside of `GridSearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = TextRNN(seed=123, cardinality=Tweet.cardinality)\n",
    "lstm.load('TextRNN_best', save_dir='checkpoints/grid_search')\n",
    "acc = lstm.score(test_tweets, test_labels)\n",
    "print(acc)\n",
    "assert acc > 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload a model with different structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.load('TextRNN_0', save_dir='checkpoints/grid_search')\n",
    "acc = lstm.score(test_tweets, test_labels)\n",
    "print(acc)\n",
    "assert acc < 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `GenerativeModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `GridSearch` on crowdsourcing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_label_matrix\n",
    "import numpy as np\n",
    "\n",
    "L_train = load_label_matrix(session, split=0)\n",
    "train_labels = np.load('crowdsourcing_train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "# Searching over learning rate\n",
    "searcher = GridSearch(GenerativeModel, {'epochs': [0, 10, 30]}, L_train)\n",
    "\n",
    "# Use training set labels here (just for testing)\n",
    "gen_model, run_stats = searcher.fit(L_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = gen_model.score(L_train, train_labels)\n",
    "print(acc)\n",
    "assert acc > 0.97"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
